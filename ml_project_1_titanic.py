# -*- coding: utf-8 -*-
"""ML_Project_1_TITANIC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l29zeRomKBvR6RK0vteL3G1VjlQJR5C9

## Coding Standards
We want to have clear and defined standards so we both understand clearly what the other is doing. We may have some questions, but before asking the code anotations must be clear enough to solve most of the issues.

* 1/ We have to explain with we are using these functions
* 2/ We must comment the code and explain it
* 3/ The code must remain clean and sorted
* 4/ We must put a bit of storytelling in the code

## What are we really trying to do

* We want to gain knowledgable skills in Machine Learning and learn the basics with this one. It's the first step to create more complex and interesing algorithms.

## What succes looks like

* Money, fame...lol. Having a good portfolio of ML and AI projects. Ultimately we want to publish our wor on LinkedIn, GitHub, or Kaggle.
* Leraning things and becoming an expert in Machine Learning and AI.

## How do we want to achieve it

* Collaborate, communicate and set clear goals and next steps.

## Next steps
* Clear, set, order data and make vizualisation.

-----------------------------------------------------------------------------

Package Import
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""Import data"""

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""* Find the current directory where the code is running.
* Read the data from the CSV file into a pandas DataFrame named gender_df.
"""

current_directory = os.getcwd()
gender_path = os.path.join(current_directory, 'gender_submission.csv')
gender_df = pd.read_csv(gender_path)
gender_df.head()

"""**Read the data from the CSV file into a pandas DataFrame named test_df.**"""

train_path = os.path.join(current_directory, 'train.csv')
train_df = pd.read_csv(train_path)
train_df.head()

"""**Read the data from the CSV file into a pandas DataFrame named train_df.**"""

test_path = os.path.join(current_directory, 'test.csv')
test_df = pd.read_csv(test_path)
test_df.head()

"""We define the variable "women" by locating the "female" in column sex. Then we extract the survival information in the "Survived" column.
Next we calculate the percentage of "women" that survived and print it.

Then we do the same for men.
"""

women = train_df.loc[train_df.Sex == 'female']["Survived"]
rate_women = sum(women)/len(women)
print(f"The percentage of women who survived is :", f"{rate_women:.0%}")

men = train_df.loc[train_df.Sex == 'male']["Survived"]
rate_men = sum(men)/len(men)
print(f"The percentage of men who survived is :", f"{rate_men:.0%}")

# Group the data by class and sex, then count passengers
class_sex_counts = train_df.groupby(['Pclass', 'Sex'])['PassengerId'].count().reset_index()

# Rename the count column for clarity
class_sex_counts.rename(columns={'PassengerId': 'Count'}, inplace=True)

# Calculate total passengers in each class
class_totals = class_sex_counts.groupby('Pclass')['Count'].sum().reset_index()

# Rename the count column for clarity
class_totals.rename(columns={'Count': 'Total'}, inplace=True)

# Merge the two DataFrames to have class totals and sex counts in one DataFrame
final_df = pd.merge(class_sex_counts, class_totals, on='Pclass')

# Calculate the percentage of men and women in each class
final_df['Percentage'] = (final_df['Count'] / final_df['Total']) * 100

# Display the results
print(final_df[['Pclass', 'Sex', 'Percentage']])

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

# We define the target variable "y" i.e the value we are trying to predict
y = train_df["Survived"]

# We define the input "x" that are going to be used in the model
features = ["Pclass", "Sex", "SibSp", "Parch"]

# get_dummies transform the categorical variables into numerical representations.
X = pd.get_dummies(train_df[features]) #train data
X_test = pd.get_dummies(test_df[features]) # test data


model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)
# n_estimators -> number of decision trees in the forest
# max_depth -> maximum depth of decision trees
# random_state -> seed for the random number generator
model.fit(X, y) # we train the model using X (train_df) to estimate y

predictions = model.predict(X_test) # Finally we use the trained model from train_df to estimate the output on the test_df.

output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})
output.to_csv('submission.csv', index=False)
print("Your submission was successfully saved!")

output.head()

"""# Random Forest Visualization

We import needed packages for the visualization
"""

from sklearn.tree import export_graphviz
import graphviz

# Access and export the first tree
dot_data = export_graphviz(model.estimators_[0],
                           feature_names=X.columns,
                           class_names=['Did not survive', 'Survived'],
                           filled=True,
                           rounded=True,
                           special_characters=True)

# Create and display the graph
graph = graphviz.Source(dot_data)
graph

# prompt: Export in pdf the graph : graph

# Assuming the graph object 'graph' from your code is still in memory.
graph.render("decision_tree", format="pdf")